{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1646b2-a34e-4893-9b7a-4926a4c09876",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "\n",
    "# Code to detect backsteps \n",
    "#    - Also need to figure out how that affects the balance/stability physics (from a coaching and movement perspective) and decide what to draw.\n",
    "\n",
    "# Scale drawings based on output resolution\n",
    "\n",
    "# Figure out how to make it more useful\n",
    "#    - Make things more self-evident for end-users, so it doesn't require a coach's eye\n",
    "#    - I need to think about how to turn my implicit knowledge into explicit knowledge and instruction\n",
    "\n",
    "# Consider better implementation of CoG tracking?\n",
    "\n",
    "# Add force vector display based on CoG\n",
    "#    - Have a dead zone and then once the CoG moves outside dead zone, show a force arrow, colored to indicate speed/force?\n",
    "\n",
    "# Look into models that can better handle holds, occlusions, & understanding of 3D space which will certainly be present in climbing footage\n",
    "#    - MediaPipe misreads holds as body parts, particulary when dealing with occlusions\n",
    "#    - Currently playing with YOLO_NAS. Handling multiple people in frame might be important for real-life footage (spotters, etc.)\n",
    "#        - If MediaPipe grabs the spotter or a person walking through frame instead of the climber, it's useless\n",
    "\n",
    "# Develop basic UI\n",
    "#    - Basic File Select & Process UI\n",
    "#    - There's probably existing video comparison software that would be better than aything I can do\n",
    "#    - Allow side by side video playing with individual scrubbing\n",
    "#    - Allow Slow-Mo and Frame-by-Frame movement\n",
    "#    - Perhaps allow selection of two processed videos and have another tab for running the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb077653-c386-4452-9b59-c25b7cfc2931",
   "metadata": {},
   "source": [
    "## Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb1caac-8b2f-4fa8-9e85-3bd41b350e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = '/path/to/.mp4'\n",
    "output_video_path = '/path/to/.mp4'\n",
    "desired_width = 'width'  # Set an integer value or 'width' for original width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-newsletter",
   "metadata": {},
   "source": [
    "# Refactor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "enabling-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "def initialize_video(input_path, desired_width):\n",
    "    \"\"\"\n",
    "    Initializes video capture from a file or camera and calculates new dimensions.\n",
    "    \n",
    "    :param input_path: Path to the video file or camera index.\n",
    "    :param desired_width: Desired width of the output frames.\n",
    "    :return: Tuple of video capture object, new dimensions (width, height).\n",
    "    \"\"\"\n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(\"Unable to open  source: {}\".format(input_path))\n",
    "\n",
    "    # Read the first frame to get original dimensions\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        raise ValueError(\"Unable to read from video source: {}\".format(input_path))\n",
    "\n",
    "    # Original dimensions\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    if desired_width == 'width':\n",
    "        # Use the original width\n",
    "        new_width = width\n",
    "        new_height = height\n",
    "    else:\n",
    "        # Calculate the new dimensions preserving aspect ratio\n",
    "        aspect_ratio = width / height\n",
    "        new_width = desired_width\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "\n",
    "    return cap, (new_width, new_height)\n",
    "\n",
    "\n",
    "def initialize_pose():\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    return pose\n",
    "\n",
    "def process_pose(frame, pose, new_dimensions):\n",
    "    \"\"\"\n",
    "    Processes a frame with MediaPipe Pose to extract keypoints.\n",
    "\n",
    "    :param frame: The video frame to process.\n",
    "    :param pose: The MediaPipe Pose object.\n",
    "    :param new_dimensions: New dimensions (width, height) to resize the frame.\n",
    "    :return: Tuple of the processed frame and extracted landmarks.\n",
    "    \"\"\"\n",
    "    # Resize the frame to new dimensions\n",
    "    frame_resized = cv2.resize(frame, new_dimensions)\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Pose\n",
    "    results = pose.process(frame_rgb)\n",
    "\n",
    "    # Convert the frame back to BGR\n",
    "    frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Extract landmarks if any are detected\n",
    "    landmarks = results.pose_landmarks.landmark if results.pose_landmarks else None\n",
    "\n",
    "    return frame_bgr, results, landmarks\n",
    "\n",
    "def calculate_joint_angle(a, b, c):\n",
    "    \"\"\"\n",
    "    Calculates the angle at joint 'b' given points a, b, c.\n",
    "\n",
    "    :param a: The first keypoint (as a tuple or list).\n",
    "    :param b: The middle keypoint (joint) where the angle is calculated.\n",
    "    :param c: The third keypoint (as a tuple or list).\n",
    "    :return: Calculated angle in degrees.\n",
    "    \"\"\"\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "     \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle \n",
    "\n",
    "\n",
    "def calculate_belly_button(hips, shoulders):\n",
    "    \"\"\"\n",
    "    Calculate the 'belly_button' keypoint.\n",
    "\n",
    "    :param hips: Coordinates of the center of the hips (tuple or list).\n",
    "    :param shoulders: Coordinates of the center of the shoulders (tuple or list).\n",
    "    :return: Coordinates of the 'belly_button' keypoint.\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays for vector operations\n",
    "    hips = np.array(hips)\n",
    "    shoulders = np.array(shoulders)\n",
    "\n",
    "    # Calculate belly button position\n",
    "    belly_button = hips + 0.25 * (shoulders - hips)\n",
    "    return belly_button.tolist()  # Convert back to list for consistency\n",
    "\n",
    "def update_cog_trajectory(processed_frame, belly_button, cog_positions, trail_length=150, trail_fade=True):\n",
    "    \"\"\"\n",
    "    Update and draw the trajectory of the Center of Gravity (CoG) using the belly_button point.\n",
    "\n",
    "    :param processed_frame: The frame to draw on.\n",
    "    :param belly_button: Current position of the CoG (belly button).\n",
    "    :param cog_positions: List storing the positions of the CoG.\n",
    "    :param trail_length: The number of past positions to include in the trail.\n",
    "    :param trail_fade: Whether to fade the trail as it gets older.\n",
    "    :return: Updated frame with CoG and trajectory.\n",
    "    \"\"\"\n",
    "    # Append the current CoG position\n",
    "    cog_positions.append(belly_button)\n",
    "\n",
    "    # Limit the length of the trail\n",
    "    if len(cog_positions) > trail_length:\n",
    "        cog_positions.pop(0)\n",
    "\n",
    "    # Draw the CoG trajectory\n",
    "    for i in range(1, len(cog_positions)):\n",
    "        opacity = 1 if not trail_fade else i / len(cog_positions)\n",
    "        color = (255, 0, 0, int(255 * opacity))  # Blue with variable opacity\n",
    "        start_point = (int(cog_positions[i-1][0]), int(cog_positions[i-1][1]))\n",
    "        end_point = (int(cog_positions[i][0]), int(cog_positions[i][1]))\n",
    "        cv2.line(processed_frame, start_point, end_point, color[:3], thickness=2)\n",
    "\n",
    "    # Draw the current CoG position\n",
    "    cv2.circle(processed_frame, (int(belly_button[0]), int(belly_button[1])), radius=5, color=(0, 255, 0), thickness=-1)  # Green\n",
    "\n",
    "    return processed_frame\n",
    "\n",
    "# Initialize an empty list outside of your processing loop to store CoG positions\n",
    "cog_positions = []\n",
    "\n",
    "\n",
    "def draw_triangle_with_color(image, belly_button, left_ankle, right_ankle, opacity=0.25):\n",
    "    \"\"\"\n",
    "    Draws a triangle using the belly button and both ankles with specified opacity. \n",
    "    The color of the triangle is green if the belly button is horizontally within the ankles, otherwise red.\n",
    "\n",
    "    :param image: The image to draw on.\n",
    "    :param belly_button: Coordinates of the belly button.\n",
    "    :param left_ankle: Coordinates of the left ankle.\n",
    "    :param right_ankle: Coordinates of the right ankle.\n",
    "    :param opacity: Opacity of the triangle.\n",
    "    :return: Image with the triangle drawn.\n",
    "    \"\"\"\n",
    "    # Convert points to numpy arrays for easier manipulation\n",
    "    belly_button = np.array(belly_button, dtype=np.int32)\n",
    "    left_ankle = np.array(left_ankle, dtype=np.int32)\n",
    "    right_ankle = np.array(right_ankle, dtype=np.int32)\n",
    "\n",
    "    # Check if belly button is horizontally within the ankles\n",
    "    if left_ankle[0] <= belly_button[0] <= right_ankle[0] or right_ankle[0] <= belly_button[0] <= left_ankle[0]:\n",
    "        color = (255, 0, 0)  # Blue\n",
    "    else:\n",
    "        color = (0, 0, 255)  # Red\n",
    "\n",
    "    # Create an overlay for the triangle\n",
    "    overlay = image.copy()\n",
    "    points = np.array([left_ankle, right_ankle, belly_button])\n",
    "    cv2.fillPoly(overlay, [points], color)\n",
    "\n",
    "    # Blend the overlay with the original image\n",
    "    cv2.addWeighted(overlay, opacity, image, 1 - opacity, 0, image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def draw_angle(image, angle, position, offset=(0, 0)):\n",
    "    \"\"\"\n",
    "    Draws the specified angle on the image at the given position.\n",
    "\n",
    "    :param image: The image to draw on.\n",
    "    :param angle: The calculated angle to draw.\n",
    "    :param position: The position (x, y) to place the angle text.\n",
    "    :param offset: Offset (x, y) to adjust the position of the text.\n",
    "    :return: Image with angle drawn.\n",
    "    \"\"\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    thickness = 2\n",
    "    color = (255, 255, 255)  # White\n",
    "\n",
    "    # Apply offset to position\n",
    "    text_position = (int(position[0] + offset[0]), int(position[1] + offset[1]))\n",
    "\n",
    "    # Draw angle text\n",
    "    cv2.putText(image, f\"{int(angle)}\", text_position, font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "def color_for_angle(angle, is_shoulder=False):\n",
    "    if is_shoulder:\n",
    "        # For shoulder joints, consider close to 0 as at rest\n",
    "        if angle < 30:  # You can adjust this threshold\n",
    "            return (0, 255, 0)  # Green\n",
    "        elif 30 <= angle <= 60:\n",
    "            return (0, 255, 255) # Yellow\n",
    "        else:\n",
    "            return (0, 0, 255)  # Red\n",
    "    else:\n",
    "        # For other joints\n",
    "        if 150 <= angle <= 180:\n",
    "            return (0, 255, 0)  # Green\n",
    "        elif 100 <= angle < 150:\n",
    "            return (0, 255, 255)  # Yellow\n",
    "        else:\n",
    "            return (0, 0, 255)  # Red\n",
    "\n",
    "\n",
    "def draw_skeleton(processed_frame, landmarks):\n",
    "    def draw_bone(point1, point2, color):\n",
    "        cv2.line(processed_frame, point1, point2, color, 2)\n",
    "\n",
    "    # Convert landmark positions to pixels\n",
    "    pixel_landmarks = {landmark: (int(landmarks[landmark.value].x * processed_frame.shape[1]),\n",
    "                                  int(landmarks[landmark.value].y * processed_frame.shape[0]))\n",
    "                       for landmark in mp.solutions.pose.PoseLandmark}\n",
    "\n",
    "    # Define skeleton structure and joints for angle calculations\n",
    "    skeleton = [\n",
    "        # Arms\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_SHOULDER, mp.solutions.pose.PoseLandmark.LEFT_ELBOW),\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_ELBOW, mp.solutions.pose.PoseLandmark.LEFT_WRIST),\n",
    "        (mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER, mp.solutions.pose.PoseLandmark.RIGHT_ELBOW),\n",
    "        (mp.solutions.pose.PoseLandmark.RIGHT_ELBOW, mp.solutions.pose.PoseLandmark.RIGHT_WRIST),\n",
    "        # Legs\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_HIP, mp.solutions.pose.PoseLandmark.LEFT_KNEE),\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_KNEE, mp.solutions.pose.PoseLandmark.LEFT_ANKLE),\n",
    "        (mp.solutions.pose.PoseLandmark.RIGHT_HIP, mp.solutions.pose.PoseLandmark.RIGHT_KNEE),\n",
    "        (mp.solutions.pose.PoseLandmark.RIGHT_KNEE, mp.solutions.pose.PoseLandmark.RIGHT_ANKLE),\n",
    "        # Torso and Hip-Shoulder Connections\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_SHOULDER, mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER),\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_HIP, mp.solutions.pose.PoseLandmark.RIGHT_HIP),\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_SHOULDER, mp.solutions.pose.PoseLandmark.LEFT_HIP),\n",
    "        (mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER, mp.solutions.pose.PoseLandmark.RIGHT_HIP),\n",
    "    ]\n",
    "\n",
    "    # Joints for angle calculations\n",
    "    joints = [\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_SHOULDER, mp.solutions.pose.PoseLandmark.LEFT_HIP, mp.solutions.pose.PoseLandmark.LEFT_ELBOW),\n",
    "        (mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER, mp.solutions.pose.PoseLandmark.RIGHT_HIP, mp.solutions.pose.PoseLandmark.RIGHT_ELBOW),\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_HIP, mp.solutions.pose.PoseLandmark.LEFT_SHOULDER, mp.solutions.pose.PoseLandmark.LEFT_KNEE),\n",
    "        (mp.solutions.pose.PoseLandmark.RIGHT_HIP, mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER, mp.solutions.pose.PoseLandmark.RIGHT_KNEE),\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_ELBOW, mp.solutions.pose.PoseLandmark.LEFT_SHOULDER, mp.solutions.pose.PoseLandmark.LEFT_WRIST),\n",
    "        (mp.solutions.pose.PoseLandmark.RIGHT_ELBOW, mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER, mp.solutions.pose.PoseLandmark.RIGHT_WRIST),\n",
    "        (mp.solutions.pose.PoseLandmark.LEFT_KNEE, mp.solutions.pose.PoseLandmark.LEFT_HIP, mp.solutions.pose.PoseLandmark.LEFT_ANKLE),\n",
    "        (mp.solutions.pose.PoseLandmark.RIGHT_KNEE, mp.solutions.pose.PoseLandmark.RIGHT_HIP, mp.solutions.pose.PoseLandmark.RIGHT_ANKLE),\n",
    "    ]\n",
    "\n",
    "    # Calculate angles for joints\n",
    "    joint_angles = {}\n",
    "    for joint in joints:\n",
    "        if all(pixel_landmarks.get(j) for j in joint):\n",
    "            joint_angles[joint[0]] = calculate_joint_angle(pixel_landmarks[joint[1]], pixel_landmarks[joint[0]], pixel_landmarks[joint[2]])\n",
    "\n",
    "    # Draw each bone with color based on joint angles\n",
    "    for limb in skeleton:\n",
    "        if all(pixel_landmarks.get(point) for point in limb):\n",
    "            point1, point2 = pixel_landmarks[limb[0]], pixel_landmarks[limb[1]]\n",
    "            # Determine if this bone is part of a joint we have an angle for\n",
    "            angle = joint_angles.get(limb[0]) or joint_angles.get(limb[1])\n",
    "            is_shoulder = limb[0] in [mp.solutions.pose.PoseLandmark.LEFT_SHOULDER, mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "            color = color_for_angle(angle, is_shoulder) if angle is not None else (255, 255, 255)  # Default color\n",
    "            draw_bone(point1, point2, color)\n",
    "\n",
    "    return processed_frame\n",
    "\n",
    "def process_video(cap, out, pose, new_dimensions):\n",
    "    # Initialize drawing utility\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process the frame to get pose results and landmarks\n",
    "        processed_frame, results, landmarks = process_pose(frame, pose, new_dimensions)\n",
    "\n",
    "        if landmarks:\n",
    "            # Extract keypoints\n",
    "            left_shoulder = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value].x * new_dimensions[0],\n",
    "                             landmarks[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value].y * new_dimensions[1]]\n",
    "            right_shoulder = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value].x * new_dimensions[0],\n",
    "                              landmarks[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value].y * new_dimensions[1]]\n",
    "            left_elbow = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_ELBOW.value].x * new_dimensions[0],\n",
    "                          landmarks[mp.solutions.pose.PoseLandmark.LEFT_ELBOW.value].y * new_dimensions[1]]\n",
    "            right_elbow = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_ELBOW.value].x * new_dimensions[0],\n",
    "                           landmarks[mp.solutions.pose.PoseLandmark.RIGHT_ELBOW.value].y * new_dimensions[1]]\n",
    "            left_wrist = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_WRIST.value].x * new_dimensions[0],\n",
    "                          landmarks[mp.solutions.pose.PoseLandmark.LEFT_WRIST.value].y * new_dimensions[1]]\n",
    "            right_wrist = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_WRIST.value].x * new_dimensions[0],\n",
    "                           landmarks[mp.solutions.pose.PoseLandmark.RIGHT_WRIST.value].y * new_dimensions[1]]\n",
    "            left_hip = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP.value].x * new_dimensions[0],\n",
    "                        landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP.value].y * new_dimensions[1]]\n",
    "            right_hip = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP.value].x * new_dimensions[0],\n",
    "                         landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP.value].y * new_dimensions[1]]\n",
    "            left_ankle = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value].x * new_dimensions[0],\n",
    "                          landmarks[mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value].y * new_dimensions[1]]\n",
    "            right_ankle = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value].x * new_dimensions[0],\n",
    "                           landmarks[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value].y * new_dimensions[1]]\n",
    "            left_knee = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_KNEE.value].x * new_dimensions[0],\n",
    "                         landmarks[mp.solutions.pose.PoseLandmark.LEFT_KNEE.value].y * new_dimensions[1]]\n",
    "            right_knee = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_KNEE.value].x * new_dimensions[0],\n",
    "                          landmarks[mp.solutions.pose.PoseLandmark.RIGHT_KNEE.value].y * new_dimensions[1]]\n",
    "\n",
    "            \n",
    "            # Calculate additional angles\n",
    "            left_knee_angle = calculate_joint_angle(left_hip, left_knee, left_ankle)\n",
    "            right_knee_angle = calculate_joint_angle(right_hip, right_knee, right_ankle)\n",
    "            left_hip_angle = calculate_joint_angle(left_shoulder, left_hip, left_knee)\n",
    "            right_hip_angle = calculate_joint_angle(right_shoulder, right_hip, right_knee)\n",
    "            left_shoulder_angle = calculate_joint_angle(left_elbow, left_shoulder, left_hip)\n",
    "            right_shoulder_angle = calculate_joint_angle(right_elbow, right_shoulder, right_hip)\n",
    "            left_elbow_angle = calculate_joint_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle = calculate_joint_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        \n",
    "            # Draw additional angles\n",
    "            processed_frame = draw_angle(processed_frame, left_knee_angle, left_knee)\n",
    "            processed_frame = draw_angle(processed_frame, right_knee_angle, right_knee)\n",
    "            processed_frame = draw_angle(processed_frame, left_hip_angle, left_hip)\n",
    "            processed_frame = draw_angle(processed_frame, right_hip_angle, right_hip)\n",
    "            processed_frame = draw_angle(processed_frame, left_shoulder_angle, left_shoulder)\n",
    "            processed_frame = draw_angle(processed_frame, right_shoulder_angle, right_shoulder)\n",
    "            processed_frame = draw_angle(processed_frame, left_elbow_angle, left_elbow)\n",
    "            processed_frame = draw_angle(processed_frame, right_elbow_angle, right_elbow)\n",
    "        \n",
    "            # Calculate belly button position\n",
    "            hips_center = [(left_hip[0] + right_hip[0]) / 2, (left_hip[1] + right_hip[1]) / 2]\n",
    "            shoulders_center = [(left_shoulder[0] + right_shoulder[0]) / 2, (left_shoulder[1] + right_shoulder[1]) / 2]\n",
    "            belly_button = calculate_belly_button(hips_center, shoulders_center)\n",
    "            processed_frame = update_cog_trajectory(processed_frame, belly_button, cog_positions)\n",
    "\n",
    "            # Draw a white line going straight down from the belly button\n",
    "            line_start = (int(belly_button[0]), int(belly_button[1]))\n",
    "            line_end = (int(belly_button[0]), int(belly_button[1]) + 200)\n",
    "            cv2.line(processed_frame, line_start, line_end, (255, 255, 255), 2)\n",
    "\n",
    "            # Draw triangle with color based on belly button position\n",
    "            processed_frame = draw_triangle_with_color(processed_frame, belly_button, left_ankle, right_ankle)\n",
    "            #processed_frame = draw_triangle_with_color(processed_frame, belly_button, left_wrist, right_wrist)\n",
    "\n",
    "            processed_frame = draw_skeleton(processed_frame, landmarks)\n",
    "        # Write the processed frame to the output file\n",
    "        out.write(processed_frame)\n",
    "\n",
    "    # Release the video capture and writer objects\n",
    "    cap.release()\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d13f7be-ba90-4185-a6fa-27eeda20d7d2",
   "metadata": {},
   "source": [
    "## Attempt to Auto-detect Frame Rate - Needs more testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195d8016-4f76-4caf-a326-965467e7f656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708961200.702224   60329 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1708961200.706664   60378 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 22.3.6), renderer: Mesa Intel(R) HD Graphics 5500 (BDW GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    # Initialize video capture and new dimensions\n",
    "    cap, new_dimensions = initialize_video(input_video_path, desired_width)\n",
    "\n",
    "    # Get input video frame rate\n",
    "    input_frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Initialize MediaPipe pose\n",
    "    pose = initialize_pose()\n",
    "\n",
    "    # Define the codec and create VideoWriter object with input frame rate\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, input_frame_rate, new_dimensions)\n",
    "\n",
    "    try:\n",
    "        # Process the video\n",
    "        process_video(cap, out, pose, new_dimensions)\n",
    "    finally:\n",
    "        # Clean up. Release video capture and writer\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65999dea-092c-47fd-beac-80de3a81a240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
